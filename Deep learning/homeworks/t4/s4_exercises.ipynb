{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YluThavSflVm"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THuSWSyZh3Gl"
      },
      "source": [
        "### Exercise: Load and Preview the California Housing Dataset\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1. Read the dataset file `california_housing_train.csv` using the `pandas` library.\n",
        "2. Print the first 5 rows of the dataset.\n",
        "\n",
        "**Expected Output:**\n",
        "\n",
        "The first 5 rows of the dataset should be displayed, showing columns like `longitude`, `latitude`, `housing_median_age`, etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "z8icG7raSQSB",
        "outputId": "0935913f-3ec6-476d-9dc6-690d8754c805"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "      <td>66900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "      <td>80100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "      <td>85700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "      <td>73400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "      <td>65500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
              "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
              "2    -114.56     33.69                17.0        720.0           174.0   \n",
              "3    -114.57     33.64                14.0       1501.0           337.0   \n",
              "4    -114.57     33.57                20.0       1454.0           326.0   \n",
              "\n",
              "   population  households  median_income  median_house_value  \n",
              "0      1015.0       472.0         1.4936             66900.0  \n",
              "1      1129.0       463.0         1.8200             80100.0  \n",
              "2       333.0       117.0         1.6509             85700.0  \n",
              "3       515.0       226.0         3.1917             73400.0  \n",
              "4       624.0       262.0         1.9250             65500.0  "
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "cl_data=pd.read_csv(r\"/home/kasra/Desktop/tahlil-dade/Deep learning/homeworks/t4/california_housing_train.csv\")\n",
        "cl_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSnhsBQ2TMbF",
        "outputId": "07d47f6c-64cf-4da7-f8e3-7bcce1ff9bd7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
              "       'total_bedrooms', 'population', 'households', 'median_income',\n",
              "       'median_house_value'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cl_data.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ8OK_s3iVHN"
      },
      "source": [
        "### Exercise: Separate Features (X) and Target (y)\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1. Use the California housing dataset loaded in the previous step.\n",
        "2. Define `X` as the feature matrix by removing the target column.\n",
        "3. Define `y` as the target vector. The target column is usually named `median_house_value`.\n",
        "\n",
        "**Expected Output:**\n",
        "\n",
        "- `X` should be a DataFrame containing all columns **except** `median_house_value`.\n",
        "- `y` should be a Series containing only the `median_house_value` column.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yD2hb461TYuP"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0    66900.0\n",
              " 1    80100.0\n",
              " 2    85700.0\n",
              " 3    73400.0\n",
              " 4    65500.0\n",
              " Name: median_house_value, dtype: float64,\n",
              "    longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              " 0    -114.31     34.19                15.0       5612.0          1283.0   \n",
              " 1    -114.47     34.40                19.0       7650.0          1901.0   \n",
              " 2    -114.56     33.69                17.0        720.0           174.0   \n",
              " 3    -114.57     33.64                14.0       1501.0           337.0   \n",
              " 4    -114.57     33.57                20.0       1454.0           326.0   \n",
              " \n",
              "    population  households  median_income  \n",
              " 0      1015.0       472.0         1.4936  \n",
              " 1      1129.0       463.0         1.8200  \n",
              " 2       333.0       117.0         1.6509  \n",
              " 3       515.0       226.0         3.1917  \n",
              " 4       624.0       262.0         1.9250  )"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X=cl_data.drop(columns=[\"median_house_value\"])\n",
        "y = cl_data[\"median_house_value\"]\n",
        "y.head() , X.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9Ksj8TFixd9"
      },
      "source": [
        "Print the first 5 rows of the x."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_PhCI1QyjEKV"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
              "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
              "2    -114.56     33.69                17.0        720.0           174.0   \n",
              "3    -114.57     33.64                14.0       1501.0           337.0   \n",
              "4    -114.57     33.57                20.0       1454.0           326.0   \n",
              "\n",
              "   population  households  median_income  \n",
              "0      1015.0       472.0         1.4936  \n",
              "1      1129.0       463.0         1.8200  \n",
              "2       333.0       117.0         1.6509  \n",
              "3       515.0       226.0         3.1917  \n",
              "4       624.0       262.0         1.9250  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCca3Z2EjCwl"
      },
      "source": [
        "### Exercise: Print the Shape of Feature Matrix X\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1. Using the feature matrix `X` defined earlier, print its shape (number of rows and columns).\n",
        "\n",
        "**Expected Output:**\n",
        "\n",
        "- The output should display a tuple showing the dimensions of `X`, for example `(17000, 8)` indicating 17,000 rows and 8 columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGkXENicTfBk",
        "outputId": "ce5fc2c8-65e4-4e23-bf19-52e480e5c498"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(17000, 8)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rcdiu8ejSQd"
      },
      "source": [
        "### Exercise: Split the Dataset into Training and Test Sets\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1. Split the dataset into training and test sets.\n",
        "2. Use 20% of the data as the test set.\n",
        "3. Use `train_test_split` from `sklearn.model_selection` for splitting.\n",
        "\n",
        "**Expected Output:**\n",
        "\n",
        "- You should have four variables: `X_train`, `X_test`, `y_train`, and `y_test`.\n",
        "- The test set should contain approximately 20% of the samples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZAGrTvKPjT-m"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train , X_test , y_train , y_test = train_test_split(X,y,random_state=42,test_size=.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pe04stn7je19"
      },
      "source": [
        "### Exercise: Define the Device for PyTorch\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1. Import `torch` library.\n",
        "2. Define a variable `device` that uses GPU if available, otherwise CPU.\n",
        "3. Print the selected device.\n",
        "\n",
        "**Expected Output:**\n",
        "\n",
        "- The output should show either `cuda` (if GPU is available) or `cpu`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "SAWXhPl-kgPt"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Aug 10 20:25:00 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 575.64.03              Driver Version: 575.64.03      CUDA Version: 12.9     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA GeForce RTX 3050 ...    Off |   00000000:01:00.0 Off |                  N/A |\n",
            "| N/A   52C    P8              8W /   30W |     119MiB /   4096MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|    0   N/A  N/A            1553      G   /usr/lib/Xorg                            22MiB |\n",
            "|    0   N/A  N/A            1633    C+G   ...b/gnome-remote-desktop-daemon         69MiB |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-iTKpjQkiYF"
      },
      "source": [
        "### Exercise: Convert Training Data to PyTorch Tensors (with Correct Shape)\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1. Convert the training feature matrix `X_train` and the target vector `y_train` to PyTorch tensors.\n",
        "2. Ensure that `X_train_tensor` has data type `float32` and shape `(n_samples, n_features)`.\n",
        "3. Ensure that `y_train_tensor` has shape `(n_samples, 1)` (i.e., two-dimensional).\n",
        "4. Move both tensors to the appropriate `device` (CPU or GPU).\n",
        "\n",
        "**Expected Output:**\n",
        "\n",
        "- `X_train_tensor`: a 2D tensor of shape `[number_of_samples, number_of_features]`.\n",
        "- `y_train_tensor`: a 2D tensor of shape `[number_of_samples, 1]`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "vVWAYiZok03-"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[-1.1807e+02,  3.3810e+01,  2.2000e+01,  ...,  1.3050e+03,\n",
              "           3.6800e+02,  8.5407e+00],\n",
              "         [-1.1763e+02,  3.3500e+01,  1.2000e+01,  ...,  1.5060e+03,\n",
              "           4.9200e+02,  7.2013e+00],\n",
              "         [-1.1709e+02,  3.2570e+01,  1.7000e+01,  ...,  3.5700e+02,\n",
              "           8.7000e+01,  5.1478e+00],\n",
              "         ...,\n",
              "         [-1.1815e+02,  3.3910e+01,  3.8000e+01,  ...,  7.6000e+02,\n",
              "           2.0800e+02,  2.9643e+00],\n",
              "         [-1.1707e+02,  3.2560e+01,  9.0000e+00,  ...,  3.2930e+03,\n",
              "           8.4000e+02,  3.0992e+00],\n",
              "         [-1.2241e+02,  3.7750e+01,  5.2000e+01,  ...,  1.9320e+03,\n",
              "           5.4900e+02,  2.3903e+00]], device='cuda:0'),\n",
              " torch.Size([13600, 8]),\n",
              " tensor([398800., 353600., 138900.,  ..., 147400., 142600., 236100.],\n",
              "        device='cuda:0'),\n",
              " torch.Size([13600]))"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_tensor = torch.tensor(X_train.values,dtype=torch.float32,device=device)\n",
        "y_train_tensor = torch.tensor(y_train.values,dtype=torch.float32,device=device)\n",
        "\n",
        "X_train_tensor , X_train_tensor.shape , y_train_tensor , y_train_tensor.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQBhWPnMk-S-"
      },
      "source": [
        "### Exercise: Build a Neural Network Model with 3 Layers\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1. Build a PyTorch neural network model.\n",
        "2. The architecture should include 3 layers:\n",
        "   - First layer: 5 neurons with ReLU activation\n",
        "   - Second layer: 3 neurons with ReLU activation\n",
        "   - Final layer: 1 neuron (no activation function)\n",
        "3. Do **not** apply any activation function to the output layer.\n",
        "\n",
        "**Expected Output:**\n",
        "\n",
        "- A model object containing 3 layers.\n",
        "- The output of the model should be a single continuous value suitable for regression.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "jF2jnvQtYEwE"
      },
      "outputs": [],
      "source": [
        "from torch import optim\n",
        "from torch import nn\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "class manual_reg(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.f1 = nn.Linear(in_features= 8,out_features=3)\n",
        "        self.f2 = nn.Linear(in_features= 3,out_features=1)\n",
        "        self.f3 = nn.Linear(in_features= 1,out_features=1)\n",
        "        self.Relu = nn.ReLU()\n",
        "    def forward(self,x):\n",
        "\n",
        "        x=self.Relu(self.f1(x)) \n",
        "        x=self.Relu(self.f2(x)) \n",
        "        x=self.f3(x) \n",
        "        return x "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MF7W0icpqOe"
      },
      "source": [
        "### Exercise: Implement the Training Loop and Train the Model\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1. Write a training loop to train the model for **500 epochs**.\n",
        "2. Use **Mean Squared Error (MSE)** as the loss function.\n",
        "3. Use an optimizer such as **SGD**.\n",
        "4. In each epoch:\n",
        "   - Perform a forward pass.\n",
        "   - Compute the loss.\n",
        "   - Perform a backward pass.\n",
        "   - Update the model parameters.\n",
        "5. Print the loss every 50 epochs to monitor training progress.\n",
        "\n",
        "**Expected Output:**\n",
        "\n",
        "- The model should train for 500 epochs.\n",
        "- You should see printed loss values at regular intervals (e.g., every 50 epochs).\n",
        "- The loss should generally decrease over time if the model is learning properly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch import optim\n",
        "from torch import nn\n",
        "loss_fn = nn.MSELoss\n",
        "torch.manual_seed(42)\n",
        "model = manual_reg().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3O3NMMhnY-QU",
        "outputId": "f3760b97-8ce7-4bde-e964-e7789c97ba83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 13367831552.000000\n",
            "Epoch 50, Loss: 13367831552.000000\n",
            "Epoch 100, Loss: 13367831552.000000\n",
            "Epoch 150, Loss: 13367831552.000000\n",
            "Epoch 200, Loss: 13367831552.000000\n",
            "Epoch 250, Loss: 13367831552.000000\n",
            "Epoch 300, Loss: 13367831552.000000\n",
            "Epoch 350, Loss: 13367831552.000000\n",
            "Epoch 400, Loss: 13367831552.000000\n",
            "Epoch 450, Loss: 13367831552.000000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "loss_fn=nn.MSELoss()\n",
        "lr=0.01\n",
        "optimizer = optim.SGD(model.parameters(),lr = lr)\n",
        "losses = []\n",
        "epoch = 500\n",
        "\n",
        "for i in range(epoch):\n",
        "    model.train() # bring the model into train mode\n",
        "    y_pred = model(X_train_tensor)\n",
        "    loss=loss_fn(y_train_tensor,y_pred)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    losses.append(loss.detach().cpu().item())\n",
        "    \n",
        "\n",
        "    if i % 50 == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            print(f\"Epoch {i}, Loss: {loss.item():.6f}\")\n",
        "        model.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91f9amRzqsNu"
      },
      "source": [
        "### Exercise: Analyze the Training Behavior\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "After training the model for 500 epochs, observe the printed loss values over time.\n",
        "\n",
        "You are expected to see a decreasing trend in the loss, indicating that the model is learning and updating its parameters correctly.\n",
        "\n",
        "However, you might notice that:\n",
        "\n",
        "- The loss is **not decreasing significantly**, or\n",
        "- The loss remains **almost constant**, or\n",
        "- The loss shows **unexpected fluctuations**.\n",
        "\n",
        "This suggests that **learning may not be happening as expected**, even though the training loop and model definition seem correct.\n",
        "\n",
        "**Question:**\n",
        "\n",
        "What could be the reasons for the model not learning properly?\n",
        "\n",
        "- The code logic appears to be correct.\n",
        "- The model runs without errors.\n",
        "- The loss function and optimizer are standard.\n",
        "\n",
        "**Hint:** Think about the nature and scale of the input data. Neural networks are sensitive to the scale of input features. You may consider whether data **normalization or standardization** is necessary before feeding inputs into the model.\n",
        "\n",
        "Discuss what might be going wrong and how you would investigate or fix it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-124.30000305175781 37937.0\n",
            "14999.0 500001.0\n"
          ]
        }
      ],
      "source": [
        "print(X_train_tensor.min().item(), X_train_tensor.max().item())\n",
        "print(y_train_tensor.min().item(), y_train_tensor.max().item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wk8dPrl9sHD2"
      },
      "outputs": [],
      "source": [
        "# i asked chat gpt , thats HUGGGGE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y358DlWasILO"
      },
      "source": [
        "### Exercise: Manually Normalize Input Features and Target (Without sklearn)\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "In regression problems, it's important to normalize both the **input features (`X`)** and the **target (`y`)** to improve the stability and efficiency of training.\n",
        "\n",
        "You will perform **standard normalization** (zero mean and unit variance) **manually**, without using any external library such as `sklearn`.\n",
        "\n",
        "---\n",
        "\n",
        "#### 🔹 Normalization Formula:\n",
        "\n",
        "For each column (feature or target), apply:\n",
        "\n",
        "$$\n",
        "x_{\\text{normalized}} = \\frac{x - \\mu}{\\sigma}\n",
        "$$\n",
        "\n",
        "where:\n",
        "\n",
        "- \\( x \\): original value  \n",
        "- \\( \\mu \\): mean of the column (computed from `X_train` or `y_train`)  \n",
        "- \\( \\sigma \\): standard deviation of the column (computed from `X_train` or `y_train`)  \n",
        "\n",
        "---\n",
        "\n",
        "#### 🔹 Your Tasks:\n",
        "\n",
        "1. Compute the mean and standard deviation of each feature column in `X_train`.\n",
        "2. Normalize `X_train` using these values.\n",
        "3. Normalize `X_test` using the **same** mean and std from `X_train`.\n",
        "4. Compute the mean and std of `y_train`, then normalize it.\n",
        "5. Apply the same transformation to `y_test`.\n",
        "6. After normalization, convert all the data to PyTorch tensors and move them to the appropriate `device`.\n",
        "\n",
        "---\n",
        "\n",
        "#### ⚠️ Notes:\n",
        "\n",
        "- Do **not** use `sklearn.preprocessing.StandardScaler` or any similar library.\n",
        "- Normalization must be done **before converting the data to PyTorch tensors**.\n",
        "- Keep track of the mean and std values for `y` — they will be needed later to **de-normalize predictions** (e.g., for evaluation or visualization).\n",
        "- Without proper normalization, the model may fail to learn effectively, especially if feature scales differ significantly.\n",
        "\n",
        "---\n",
        "\n",
        "**Expected Output:**\n",
        "\n",
        "- Each column in `X_train` should have a mean close to 0 and standard deviation close to 1.\n",
        "- The same applies to `y_train`.\n",
        "- `X_test` and `y_test` should be transformed using `X_train` and `y_train` statistics.\n",
        "- Model training loss should now decrease more consistently compared to training without normalization.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "7kdS0YGOt32u"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "X_mean = np.mean(X_train.values, axis=0)\n",
        "X_std = np.std(X_train.values, axis=0)\n",
        "\n",
        "X_train_norm = (X_train.values - X_mean) / X_std\n",
        "X_test_norm = (X_test.values - X_mean) / X_std\n",
        "\n",
        "y_mean = np.mean(y_train.values)\n",
        "y_std = np.std(y_train.values)\n",
        "y_train_norm = (y_train.values - y_mean) / y_std\n",
        "y_test_norm = (y_test.values - y_mean) / y_std\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUOTvkg8t4eO"
      },
      "source": [
        "### Exercise: Convert Normalized Data to Tensors, Train the Model, and Plot Loss\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1. Convert the normalized `X_train`, `X_test`, `y_train`, and `y_test` data to PyTorch tensors.\n",
        "2. Move the tensors to the appropriate device (CPU or GPU).\n",
        "3. Train the model using the normalized training data.\n",
        "4. During training, record the loss value for each epoch.\n",
        "5. After training, plot the training loss curve over all epochs to visualize the learning progress.\n",
        "6. Analyze the plot to confirm that the loss decreases smoothly over time, indicating successful training.\n",
        "\n",
        "**Expected Output:**\n",
        "\n",
        "- Tensors for all datasets on the correct device.\n",
        "- A training loss plot showing a generally decreasing trend.\n",
        "- Confirmation that normalization helped stabilize and improve training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "Of4T70CIuJf1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 0.7418, -0.8472, -0.5284,  ..., -0.1093, -0.3466,  2.4434],\n",
              "         [ 0.9614, -0.9924, -1.3222,  ...,  0.0639, -0.0235,  1.7419],\n",
              "         [ 1.2309, -1.4283, -0.9253,  ..., -0.9263, -1.0787,  0.6666],\n",
              "         ...,\n",
              "         [ 0.7019, -0.8003,  0.7417,  ..., -0.5790, -0.7635, -0.4769],\n",
              "         [ 1.2409, -1.4329, -1.5604,  ...,  1.6040,  0.8831, -0.4063],\n",
              "         [-1.4240,  0.9993,  1.8530,  ...,  0.4310,  0.1250, -0.7775]],\n",
              "        device='cuda:0'),\n",
              " torch.Size([13600, 8]),\n",
              " tensor([ 1.6614,  1.2705, -0.5865,  ..., -0.5130, -0.5545,  0.2542],\n",
              "        device='cuda:0'),\n",
              " torch.Size([13600]))"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_tensor = torch.tensor(X_train_norm,dtype=torch.float32,device=device)\n",
        "y_train_tensor = torch.tensor(y_train_norm,dtype=torch.float32,device=device)\n",
        "\n",
        "X_train_tensor , X_train_tensor.shape , y_train_tensor , y_train_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "t9jUbO6buVev"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kasra/.pyenv/versions/3.10.13/lib/python3.10/site-packages/torch/nn/modules/loss.py:616: UserWarning: Using a target size (torch.Size([13600, 1])) that is different to the input size (torch.Size([13600])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 42728108032.000000\n",
            "Epoch 50, Loss: 5666580480.000000\n",
            "Epoch 100, Loss: 751499584.000000\n",
            "Epoch 150, Loss: 99663536.000000\n",
            "Epoch 200, Loss: 13217340.000000\n",
            "Epoch 250, Loss: 1752879.375000\n",
            "Epoch 300, Loss: 232466.953125\n",
            "Epoch 350, Loss: 30830.525391\n",
            "Epoch 400, Loss: 4089.595215\n",
            "Epoch 450, Loss: 543.227478\n"
          ]
        }
      ],
      "source": [
        "\n",
        "loss_fn=nn.MSELoss()\n",
        "lr=0.01\n",
        "optimizer = optim.SGD(model.parameters(),lr = lr)\n",
        "losses = []\n",
        "epoch = 500\n",
        "\n",
        "for i in range(epoch):\n",
        "    model.train() # bring the model into train mode\n",
        "    y_pred = model(X_train_tensor)\n",
        "    loss=loss_fn(y_train_tensor,y_pred)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    losses.append(loss.detach().cpu().item())\n",
        "    \n",
        "\n",
        "    if i % 50 == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            print(f\"Epoch {i}, Loss: {loss.item():.6f}\")\n",
        "        model.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUlrwIKcuV3u"
      },
      "source": [
        "### Exercise: Increase Model Complexity and Experiment with Learning Rates\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1. Modify your neural network model to make it more complex by:\n",
        "   - Increasing the number of layers (e.g., 4 or 5 layers).\n",
        "   - Increasing the number of neurons in each layer (e.g., 64, 32, 16, 8, 1).\n",
        "   - Use ReLU activation in all layers except the last.\n",
        "2. Train the model with **different learning rates** (e.g., 0.01, 0.001, 0.0001).\n",
        "3. For each learning rate:\n",
        "   - Train the model for the same number of epochs.\n",
        "   - Record the training loss over epochs.\n",
        "4. Compare and analyze the results to determine how learning rate affects the training process and final performance.\n",
        "5. Optionally, plot the training loss curves for different learning rates on the same graph for better comparison.\n",
        "\n",
        "**Expected Output:**\n",
        "\n",
        "- Multiple trained models with varying learning rates.\n",
        "- Training loss plots showing how different learning rates impact convergence speed and stability.\n",
        "- An analysis explaining which learning rate works best and why.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sl65MzwDZsY_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "pbcYEPkRaZ3W",
        "outputId": "33d6576c-ac35-451a-c5df-b2f6b7ac718f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(range(epoch), losses)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "3.10.13",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
